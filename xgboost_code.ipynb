{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "def get_xgb_model(n_tree, n_jobs=20):\n",
    "    model = xgb.XGBClassifier(\n",
    "        n_estimators=n_tree,\n",
    "        max_depth=3,\n",
    "        min_child_weight=300,\n",
    "        learning_rate=0.1,\n",
    "        n_jobs=n_jobs,\n",
    "        tree_method='hist',\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "xgb_model_A = get_xgb_model(75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def run_model(df_train,df_val,df_test,model_obj,model_feat_colms):\n",
    "    \n",
    "    # make vectors\n",
    "    y_val = df_val.label.to_numpy()\n",
    "    X_val = df_val[model_feat_colms].to_numpy()\n",
    "\n",
    "    # Make Train Vectors\n",
    "    y_train = df_train.label.to_numpy()\n",
    "    X_train = df_train[model_feat_colms].to_numpy()\n",
    "    \n",
    "    # Make Test Vectors\n",
    "    y_test = df_test.label.to_numpy()\n",
    "    X_test = df_test[model_feat_colms].to_numpy()\n",
    "\n",
    "     # train the model\n",
    "    model_obj.fit(X = X_train, y=y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred_val = model_obj.predict_proba(X_val)\n",
    "    y_pred_train = model_obj.predict_proba(X_train)\n",
    "    y_pred_test= model_obj.predict_proba(X_test)\n",
    "\n",
    "    # performance\n",
    "    auc_train = roc_auc_score(y_train,y_pred_train[:,1])\n",
    "    auc_val = roc_auc_score(y_val,y_pred_val[:,1])\n",
    "    auc_test = roc_auc_score(y_test,y_pred_test[:,1])\n",
    "\n",
    "    df_val[\"score\"] =y_pred_val[:,1]\n",
    "    df_train[\"score\"]=y_pred_train[:,1]\n",
    "    df_test[\"score\"]=y_pred_test[:,1]\n",
    "    # Feature Importances\n",
    "    feat_imp = list(zip(model_feat_colms, model_obj.feature_importances_))\n",
    "    return (auc_train, auc_test, auc_val), feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "auc_scores_A,feat_imp = run_model(model_obj=xgb_model_A,\n",
    "                                model_feat_colms=filtered_features,\n",
    "                                df_train=df_train,\n",
    "                                df_val=df_val,\n",
    "                                 df_test = df_test)\n",
    "auc_scores_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def print_metrics(true_vec, pred_vec, this_deciles, cut_off=0.5):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    n_deciles = len(this_deciles) - 1\n",
    "    pred_deciles = pd.cut(\n",
    "        np.squeeze(pred_vec), \n",
    "        this_deciles, \n",
    "        labels = range(n_deciles)\n",
    "    )\n",
    "    \n",
    "    pred_vec_cls = (pred_vec>cut_off).astype('int')\n",
    "    precision = precision_score(true_vec, pred_vec_cls)\n",
    "    recall = recall_score(true_vec, pred_vec_cls)\n",
    "    auc = roc_auc_score(true_vec, pred_vec)\n",
    "    accuracy = accuracy_score(true_vec, pred_vec_cls)\n",
    "    decile_matrix = pd.crosstab(true_vec, pred_deciles)\n",
    "    conf_matrix = pd.crosstab(true_vec, pred_vec_cls)\n",
    "    bad_rate = pd.crosstab(true_vec, pred_deciles, normalize='columns').to_numpy()[1:,][0]\n",
    "    \n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1: {2*recall*precision/(recall+precision)}')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'AUC: {auc}')\n",
    "    print(f'Confusion_matrix:\\n{conf_matrix}')\n",
    "    print(f'Decile_matrix:\\n{decile_matrix}')\n",
    "    print(f'Bad Rate:\\n{bad_rate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "decile_cuts_all_apr = [\n",
    "    0.0,\n",
    "    0.534209132194519,\n",
    "    0.569546103477478,\n",
    "    0.5933143496513367,\n",
    "    0.6123031973838806,\n",
    "    0.6289125084877014,\n",
    "    0.6502689123153687,\n",
    "    0.6742594540119169,\n",
    "    0.6988576054573059,\n",
    "    0.7518265485763549,\n",
    "    1.0\n",
    "]\n",
    "print_metrics(y_train, y_pred_tr, decile_cuts_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
